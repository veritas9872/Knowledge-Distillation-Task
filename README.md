# Knowledge-Distillation-Task
My implementation of "Distilling the Knowledge in a Neural Network" with some extra features.

This project is implemented with Pytorch 1.4 but will probably work on 1.1 or above.

Python 3.7 was used with extensive use of type hinting and f-strings.

Only CIFAR10 is implemented for this project.

Also, the teacher and student models are fixed beforehand.

To change these settings, the project will have to be modified for extra options.


